{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Slideshow",
    "colab": {
      "name": "Copy of e2e ASR homework v1",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shoutong/colabs/blob/master/Copy_of_e2e_ASR_homework_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qncY3FktdgMI"
      },
      "source": [
        "# EN. 601.467/667 Introduction to Human Language Technology\n",
        "# End-to-End Speech Recognition Toolkit\n",
        "**Deadline 16, October, 2019**\n",
        "\n",
        "- We use [ESPnet](https://github.com/espnet/espnet)\n",
        "- This homework is designed to have an overview experience of end-to-end speech recognition. Various contents are not covered in the lecture due to the limitation of time.\n",
        "- Adapted from the [Interspeech 2019 tutorial materials](https://github.com/espnet/interspeech2019-tutorial).\n",
        "  - Special thanks to Shigeki Karita and Tomoki Hayashi.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSbPo3PMxBKa",
        "colab_type": "text"
      },
      "source": [
        "## Google colaboratory\n",
        "\n",
        "Before getting started, get familiar with google colaboratory:\n",
        "https://colab.research.google.com/notebooks/welcome.ipynb\n",
        "\n",
        "- Online Jupyter notebook environment\n",
        "    - Can run python codes\n",
        "    - Can also run linux command with ! mark\n",
        "    - Can use a signal GPU (K80)\n",
        "- What you need to use\n",
        "    - Internet connection\n",
        "    - Google account\n",
        "    - Chrome browser (recommended)\n",
        "\n",
        "This is a neat python environment that works in the cloud and does not require you to\n",
        "set up anything on your personal machine\n",
        "(it also has some built-in IDE features that make writing code easier).\n",
        "Moreover, it allows you to copy any existing colaboratory file, alter it and share\n",
        "with other people. In this homework, we will ask you to copy current colaboraty,\n",
        "complete all the tasks and share your colaboratory notebook with us so\n",
        "that we can grade it.\n",
        "\n",
        "## Submission\n",
        "\n",
        "Before you start working on this homework do the following steps:\n",
        "\n",
        "1. Press __File > Save a copy in Drive...__ tab. This will allow you to have your own copy and change it.\n",
        "2. Follow all the steps in this colaboratory file and write/change/uncomment code as necessary.\n",
        "3. Do not forget to occasionally press __File > Save__ tab to save your progress.\n",
        "4. After all the changes are done and progress is saved press __Share__ button (top right corner of the page), press __get shareable link__ and make sure you have the option __Anyone with the link can view__ selected.\n",
        "5. Paste the link into your submission pdf file so that we can view it and grade.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pAOHL0Rq-6Hm"
      },
      "source": [
        "# 1. Overview\n",
        "\n",
        "ESPnet provides **bash recipes and python library** for speech processing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SlGI71D4-6Hu"
      },
      "source": [
        "## 1.1 Python library overview\n",
        "\n",
        "- Python 3.6+\n",
        "- Uses the following neural network libraries\n",
        "  - PyTorch\n",
        "  - Chainer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "USfjVUT8-6Hy"
      },
      "source": [
        "## 1.2 Bash recipe overview\n",
        "\n",
        "ESPnet supports total 34+ ASR and other speech processing tasks including\n",
        "\n",
        "- Multilingual ASR: en, zh, ja, etc\n",
        "- Noise robust and far-field ASR\n",
        "- Multichannel ASR: joint training with speech enhancement\n",
        "- Speech Translation: transfer learning from ASR and MT\n",
        "\n",
        "For more detail:\n",
        "https://github.com/espnet/espnet/tree/master/egs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lcQ6iKES-6H0"
      },
      "source": [
        "## 1.3 ASR Performance\n",
        "\n",
        "On free corpora, ESPnet achieved:\n",
        "\n",
        "- Aishell (zh): CER test: 6.7%\n",
        "- Common Voice (en): WER test: 2.3%\n",
        "- LibriSpeech (en): WER test-clean: 2.6%, test-other 5.7%\n",
        "- TED-LIUM2 (en): WER test: 8.1%\n",
        "\n",
        "**Pretrained models are available**\n",
        "\n",
        "https://github.com/espnet/espnet#asr-results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P1BzhOOn-6H4"
      },
      "source": [
        "# 2. Installation\n",
        "\n",
        "ESPnet depends on Kaldi ASR toolkit and Warp-CTC.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BWdrn8p2_HxX"
      },
      "source": [
        "## 2.1 Installation (on Google colab)\n",
        "\n",
        "In Google colab, we can use pre-compiled binaries for faster startup (3 min):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mLxx6gVHwda6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c9b9bb1b-f59a-4dd7-b867-9977bb3c1b4b"
      },
      "source": [
        "# OS setup\n",
        "!cat /etc/os-release\n",
        "!apt-get install -qq bc tree sox\n",
        "\n",
        "# espnet setup\n",
        "!git clone --depth 5 https://github.com/espnet/espnet\n",
        "!pip install -q torch==1.1\n",
        "!cd espnet; pip install -q -e .\n",
        "\n",
        "# download pre-compiled warp-ctc and kaldi tools\n",
        "!espnet/utils/download_from_google_drive.sh \\\n",
        "    \"https://drive.google.com/open?id=13Y4tSygc8WtqzvAVGK_vRV9GlV7TRC0w\" espnet/tools tar.gz > /dev/null\n",
        "!cd espnet/tools/warp-ctc/pytorch_binding && \\\n",
        "    pip install -U dist/warpctc_pytorch-0.1.1-cp36-cp36m-linux_x86_64.whl\n",
        "\n",
        "# make dummy activate\n",
        "!mkdir -p espnet/tools/venv/bin && touch espnet/tools/venv/bin/activate\n",
        "!echo \"setup done.\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.3 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.3 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libopencore-amrnb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../1-libopencore-amrwb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "Preparing to unpack .../2-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../3-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package bc.\n",
            "Preparing to unpack .../4-bc_1.07.1-2_amd64.deb ...\n",
            "Unpacking bc (1.07.1-2) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../5-libsox3_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../6-libsox-fmt-alsa_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../7-libsox-fmt-base_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../8-sox_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package tree.\n",
            "Preparing to unpack .../9-tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up bc (1.07.1-2) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Cloning into 'espnet'...\n",
            "remote: Enumerating objects: 2247, done.\u001b[K\n",
            "remote: Counting objects: 100% (2247/2247), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1751/1751), done.\u001b[K\n",
            "remote: Total 2247 (delta 676), reused 1008 (delta 274), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2247/2247), 2.54 MiB | 6.61 MiB/s, done.\n",
            "Resolving deltas: 100% (676/676), done.\n",
            "\u001b[K     |████████████████████████████████| 676.9MB 28kB/s \n",
            "\u001b[31mERROR: torchvision 0.6.0+cu101 has requirement torch==1.5.0, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 4.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 10.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 13.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 21.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6MB 22.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 419kB 38.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 41.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4MB 40.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 34.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8MB 41.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 41.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 38.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7MB 37.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 31.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 39.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 39.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.1MB 36.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 11.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 757kB 36.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 41.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 512kB 39.7MB/s \n",
            "\u001b[?25h  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for chainer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pysptk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for kaldiio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nnmnkwii (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pystoi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bandmat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for simplejson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for clint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for args (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement h5py<2.11.0,>=2.10.0, but you'll have h5py 2.9.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement protobuf>=3.8.0, but you'll have protobuf 3.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-hub 0.8.0 has requirement protobuf>=3.8.0, but you'll have protobuf 3.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboardx 2.0 has requirement protobuf>=3.8.0, but you'll have protobuf 3.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: languageflow 1.1.13a1 has requirement joblib==0.13.2, but you'll have joblib 0.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: languageflow 1.1.13a1 has requirement scikit-learn==0.20.3, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: underthesea 1.1.17 has requirement nltk<3.5,>=3.4, but you'll have nltk 3.5 which is incompatible.\u001b[0m\n",
            "--2020-06-10 11:38:42--  https://drive.google.com/uc?export=download&id=13Y4tSygc8WtqzvAVGK_vRV9GlV7TRC0w\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.13.113, 142.250.13.100, 142.250.13.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.13.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘espnet/tools/6QTsPk.tar.gz’\n",
            "\n",
            "espnet/tools/6QTsPk     [ <=>                ]   3.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-10 11:38:43 (33.2 MB/s) - ‘espnet/tools/6QTsPk.tar.gz’ saved [3094]\n",
            "\n",
            "\n",
            "gzip: stdin: not in gzip format\n",
            "tar: Child returned status 1\n",
            "tar: Error is not recoverable: exiting now\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3094    0  3094    0     0  14324      0 --:--:-- --:--:-- --:--:-- 14324\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 65632    0 65632    0     0   330k      0 --:--:-- --:--:-- --:--:-- 7348k\n",
            "\n",
            "gzip: stdin: not in gzip format\n",
            "tar: Child returned status 1\n",
            "tar: Error is not recoverable: exiting now\n",
            "/bin/bash: line 0: cd: espnet/tools/warp-ctc/pytorch_binding: No such file or directory\n",
            "setup done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_6pH9DX1hTLj"
      },
      "source": [
        "# 3. AN4 ASR experiments based on ESPnet\n",
        "\n",
        "- `espnet/egs/*/asr1/run.sh` is an out-of-the-box recipe\n",
        "- It reproduces our reported results\n",
        "\n",
        "![image.png](https://github.com/espnet/interspeech2019-tutorial/blob/master/notebooks/interspeech2019_asr/figs/stages.png?raw=1)\n",
        "\n",
        "- **stage -1**: Download data if the data is available online.\n",
        "- **stage 0**: Prepare data to make kaldi-style data directory.\n",
        "- **stage 1**: Extract feature vector, calculate statistics, and normalize.\n",
        "- **stage 2**: Prepare a dictionary and make json files for training.\n",
        "- **stage 3**: Train the language model network.\n",
        "- **stage 4**: Train the E2E-ASR network.\n",
        "- **stage 5**: Decode speech data using the trained networks and perform scoring (provide the character error rate (CER), word error rate (WER), etc.).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A_ATcz0jnCcF"
      },
      "source": [
        "## 3.1 Kaldi-style directory structure\n",
        "\n",
        "Always we organize each recipe as `egs/xxx/asr1/run.sh`\n",
        "\n",
        "The most important directories:\n",
        "- `run.sh`: Main script of the recipe.\n",
        "- `cmd.sh`: Command configuration script to control how-to-run each job.\n",
        "- `path.sh`: Path configuration script. Basically, we do not need to touch.\n",
        "- `conf/`: Directory containing configuration files e.g.g.\n",
        "- `local/`: Directory containing the recipe-specific scripts e.g. data preparation.\n",
        "- `steps/` and `utils/`: Directory containing kaldi tools.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gsVAFRyNmr_h",
        "colab": {}
      },
      "source": [
        "# move on the recipe directory\n",
        "import os\n",
        "os.chdir(\"/content/espnet/egs/an4/asr1\")\n",
        "\n",
        "# check files\n",
        "!tree -L 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WkkVjeBM_PNo"
      },
      "source": [
        "\n",
        "## 3.2 Data preparation (Stage 0 - 2)\n",
        "\n",
        "For example, if you add `--stop-stage 2`, you can stop the script before neural network training.\n",
        "\n",
        "These stages perform FBANK speech feature extraction, normalization, and text formatting.\n",
        "\n",
        "![image.png](https://github.com/espnet/interspeech2019-tutorial/blob/master/notebooks/interspeech2019_asr/figs/stages_prep.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c40PWi8wzY0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run stage -1 and then stop\n",
        "!./run.sh --stop_stage 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O88CpXHtHnZA"
      },
      "source": [
        "Now ready to start training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xdguXokUwn7V"
      },
      "source": [
        "## 3.3 NN Training (Stage 3 - 4)\n",
        "\n",
        "You can configure NN training with `conf/train_xxx.yaml`\n",
        "\n",
        "![image.png](https://github.com/espnet/interspeech2019-tutorial/blob/master/notebooks/interspeech2019_asr/figs/stages_nn.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JwHNT4fuS4e",
        "colab_type": "text"
      },
      "source": [
        "## 3.3.1 Run LM\n",
        "\n",
        "First, we train RNNLM for the AN4 data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-vNl2QcXwOGS",
        "colab": {}
      },
      "source": [
        "# it takes 2 minutes\n",
        "!./run.sh  --ngpu 1 --stage 3 --stop-stage 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvPSgyXU8XYJ",
        "colab_type": "text"
      },
      "source": [
        "After we finish the LM training, we can check the perplexity from the log file (`train.log`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFwcNkc28n8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check the LM perplexity\n",
        "!cat exp/train_rnnlm_pytorch_lm_word100/train.log | grep perplexity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dWeTSyq9g35",
        "colab_type": "text"
      },
      "source": [
        "Please check the `test perplexity` with the above command. The perplexity value should be around 14."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xxUnqdH44s1",
        "colab_type": "text"
      },
      "source": [
        "## 3.3.2 ASR NN training\n",
        "\n",
        "We train ASR NN for the AN4 data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elmKPNufuS4T",
        "colab_type": "text"
      },
      "source": [
        "## ASR training config: RNN with Attention\n",
        "\n",
        "- you can check the default config in the following command\n",
        "- (optional) complete list of common options https://espnet.github.io/espnet/apis/espnet_bin.html#asr-train-py\n",
        "- (optional) complete list of model-specific options https://espnet.github.io/espnet/_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.add_arguments\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wmi7ggV4U_pv",
        "colab": {}
      },
      "source": [
        "!cat /content/espnet/egs/an4/asr1/conf/train_mtlalpha0.5.yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTa5DlNK5L3j",
        "colab_type": "text"
      },
      "source": [
        "## Perform ASR NN training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUhOtZWN6f5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WARNING: This code takes 5-6 minutes!\n",
        "!./run.sh  --ngpu 1 --stage 4 --stop-stage 4 --train-config conf/train_mtlalpha0.5.yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvB9VGTIo8kA",
        "colab_type": "text"
      },
      "source": [
        "The training log file is stored in `exp/train_nodev_pytorch_train_mtlalpha0.5/train.log`.\n",
        "\n",
        "Let's first look at the validation result of the initial training with the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g-PFzNrleqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!grep -e groundtruth -e prediction exp/train_nodev_pytorch_train_mtlalpha0.5/train.log \\\n",
        "  | sed -e 's/<eos>//g' -e 's/<space>/ /g' | head -n 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl4nZ2WjpMVt",
        "colab_type": "text"
      },
      "source": [
        "By comparing the groundtruth and prediction results, you could see that it did not produce meaningful results.\n",
        "\n",
        "Then, let's check the validation result of the final training with the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4W7sK9vnAba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!grep -e groundtruth -e prediction exp/train_nodev_pytorch_train_mtlalpha0.5/train.log \\\n",
        "  | sed -e 's/<eos>//g' -e 's/<space>/ /g' | tail -n 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-mSPs1tpw9e",
        "colab_type": "text"
      },
      "source": [
        "Compared with the initial result, the prediction is close to the groundtruth. Training seems to be going well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4nYAZsKuS4r",
        "colab_type": "text"
      },
      "source": [
        "You can also check the training and validation accuracies from `exp/train_nodev_pytorch_train_mtlalpha0.5/results/acc.png`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YF9Nu7OeuS4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "from IPython.display import Image, display_png\n",
        "expdir = \"exp/train_nodev_pytorch_train_mtlalpha0.5/results/\"\n",
        "for name in [\"acc.png\"]:\n",
        "    print(name)\n",
        "    display_png(Image(expdir + name, width=500))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-RX1oryzt8Q",
        "colab_type": "text"
      },
      "source": [
        "Please confirm that both training and validation accuracies are improved with more epochs, but finally converged."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2TA5RO6rVzlr"
      },
      "source": [
        "## 3.4 Decoding and evaluation (Stage 5)\n",
        "\n",
        "The last stage of ASR recipe\n",
        "\n",
        "![image.png](https://github.com/espnet/interspeech2019-tutorial/blob/master/notebooks/interspeech2019_asr/figs/stages_eval.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RLxqDSsXA3Xu"
      },
      "source": [
        "### decoding config\n",
        "- you can check the default config in the following command\n",
        "- (option) complete list of common options https://espnet.github.io/espnet/apis/espnet_bin.html#asr-recog-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NHtzMEczV3D1",
        "colab": {}
      },
      "source": [
        "!cat conf/decode_ctcweight0.5.yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OHoUE27XZ3u",
        "colab_type": "text"
      },
      "source": [
        "### Language model weight\n",
        "- `lm-weight:` language model (LM) weight $\\lambda$\n",
        "\n",
        "- without LM\n",
        "\n",
        "  $\\hat{W} = \\arg \\max _{W} \\log p(W|O) = \\arg \\max _{W}  \\log p_{\\text{e2e}}(W|O)$\n",
        "\n",
        "\n",
        "- with LM\n",
        "\n",
        "  $\\hat{W} = \\arg \\max _{W} \\log p(W|O) = \\arg \\max _{W}  (\\log p_{\\text{e2e}}(W|O) + \\lambda \\log p_{\\text{lm}}(W))$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgNLfRf6uS40",
        "colab_type": "text"
      },
      "source": [
        "### Run ASR decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R-NBPjKeRGdF",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# WARNING: This code takes 6 minutes!\n",
        "# Only recognize the test set\n",
        "!sed -i.bak -e's/recog_set=\"train_dev test\"/recog_set=\"test\"/' run.sh\n",
        "# run the actual recognition script\n",
        "!./run.sh --stage 5 --decode-config conf/decode_ctcweight0.5.yaml --train-config conf/train_mtlalpha0.5.yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q--YOTde-6Jf"
      },
      "source": [
        "You can get the Character Error Rate (CER) by checking the `Err` column in the last line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WInK0cGPuS6A",
        "colab_type": "text"
      },
      "source": [
        "## 4. Compare the result w/ and w/o language model (main homework)\n",
        "\n",
        "1. modify the decoding config file by the `sed` command and set `lm-weight` to `{0.0, 0.1, 0.2, 0.3}` and rename the config appropriately\n",
        "2. perform recognition\n",
        "\n",
        "The following is an example of how to change the language model weight\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4PnchKa1bu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sed -e 's/lm-weight: 1.0/lm-weight: 0.1/' conf/decode_ctcweight0.5.yaml | tee conf/decode_ctcweight0.5_lmweight0.1.yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JqYVwcZ14Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./run.sh --stage 5 --decode-config conf/decode_ctcweight0.5_lmweight0.1.yaml --train-config conf/train_mtlalpha0.5.yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLiGcK1VxrTI",
        "colab_type": "text"
      },
      "source": [
        "**Important Note**: \n",
        "- Unfortunately, the result would be changing with different Google colab images. Please finish the above experiments in a half day (otherwise it may use a different image and results would not be consistent)"
      ]
    }
  ]
}