{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Public-phoneme-recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shoutong/colabs/blob/master/Copy_of_Public_phoneme_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM1ay2pRamzJ",
        "colab_type": "text"
      },
      "source": [
        "<center> <h1> Phoneme Recognition </h1> </center>\n",
        "\n",
        "For this homework we will build a simple [Phoneme](https://https://en.wikipedia.org/wiki/Phoneme) Recognition Neural Network.\n",
        "\n",
        "We will use the TIMIT dataset for this homework. It containts utterances form several different English speakers saying sentences (See more details [here](https://https://catalog.ldc.upenn.edu/LDC93S1)).\n",
        "\n",
        "<center> <h2> Setup </h2> </center>\n",
        "\n",
        "#### Google colaboratory\n",
        "\n",
        "Before getting started, get familiar with google colaboratory:\n",
        "https://colab.research.google.com/notebooks/welcome.ipynb\n",
        "\n",
        "This is a neat python environment that works in the cloud and does not require you to\n",
        "set up anything on your personal machine\n",
        "(it also has some built-in IDE features that make writing code easier).\n",
        "Moreover, it allows you to copy any existing collaboratory file, alter it and share\n",
        "with other people. In this homework, we will ask you to copy current colaboraty,\n",
        "complete all the tasks and share your colaboratory notebook with us so\n",
        "that we can grade it.\n",
        "\n",
        "#### Submission\n",
        "\n",
        "Before you start working on this homework do the following steps:\n",
        "\n",
        "1. Press __File > Save a copy in Drive...__ tab. This will allow you to have your own copy and change it.\n",
        "2. Follow all the steps in this collaboratory file and write/change/uncomment code as necessary.\n",
        "3. Do not forget to occasionally press __File > Save__ tab to save your progress.\n",
        "4. After all the changes are done and progress is saved press __Share__ button (top right corner of the page), press __get shareable link__ and make sure you have the option __Anyone with the link can view__ selected.\n",
        "5. Paste the link into your submission pdf file so that we can view it and grade."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIccL5GzxhR2",
        "colab_type": "code",
        "outputId": "79dd9f07-824d-418c-939f-a1e8654ef1fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "random.seed(1234)\n",
        "torch.manual_seed(1234)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5b18284370>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQHJjzD5YAKC",
        "colab_type": "text"
      },
      "source": [
        "# Dataset \n",
        "For convenience we have done some preprocessing of the TIMIT audio. In the files below, we have files `{train/dev/test}_feats.mat.npy` and `{train/dev/test}_labels.mat.npy` which contain [MFCC features](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum) and phoneme labels per frame.\n",
        "\n",
        "The segment below downloads the preprocessed data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMBltyhptzju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q -nc https://raw.githubusercontent.com/jhu-intro-hlt/jhu-intro-hlt.github.io/master/data-phone-recognitiona/dev_feats.mat.npy\n",
        "!wget -q -nc https://raw.githubusercontent.com/jhu-intro-hlt/jhu-intro-hlt.github.io/master/data-phone-recognitiona/train_feats.mat.npy\n",
        "!wget -q -nc https://raw.githubusercontent.com/jhu-intro-hlt/jhu-intro-hlt.github.io/master/data-phone-recognitiona/test_feats.mat.npy\n",
        "!wget -q -nc https://raw.githubusercontent.com/jhu-intro-hlt/jhu-intro-hlt.github.io/master/data-phone-recognitiona/dev_labels.mat.npy\n",
        "!wget -q -nc https://raw.githubusercontent.com/jhu-intro-hlt/jhu-intro-hlt.github.io/master/data-phone-recognitiona/train_labels.mat.npy\n",
        "!wget -q -nc https://raw.githubusercontent.com/jhu-intro-hlt/jhu-intro-hlt.github.io/master/data-phone-recognitiona/test_labels.mat.npy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lfG4_EWclDK",
        "colab_type": "text"
      },
      "source": [
        "Next, we define two methods to read the numpy formatted data. `get_labels` function maps each phoneme to a index (i.e. `int`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuBERKCMwFnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_labels(data):\n",
        "    label_dict = {}\n",
        "    for y in data:\n",
        "        label_dict[y] = label_dict.get(y, len(label_dict))\n",
        "    return label_dict\n",
        "\n",
        "\n",
        "def load_npy():\n",
        "    train_feats = np.load('train_feats.mat.npy', allow_pickle=True)\n",
        "    train_labels = np.load('train_labels.mat.npy', allow_pickle=True)\n",
        "    label_idx = get_labels(train_labels)\n",
        "    test_feats = np.load('test_feats.mat.npy', allow_pickle=True)\n",
        "    test_labels = np.load('test_labels.mat.npy', allow_pickle=True)\n",
        "    dev_feats = np.load('dev_feats.mat.npy', allow_pickle=True)\n",
        "    dev_labels = np.load('dev_labels.mat.npy', allow_pickle=True)\n",
        "    return label_idx, (train_feats, train_labels), (dev_feats, dev_labels), (test_feats, test_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edcfjz_PwpSt",
        "colab_type": "code",
        "outputId": "88e0049c-f427-47f1-f717-41ef39f423b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "label_dict, train, dev, test = load_npy()\n",
        "\n",
        "#Display the shape of the features and labels\n",
        "print(train[0].shape, len(train[1]))\n",
        "print(dev[0].shape, len(dev[1]))\n",
        "print(test[0].shape, len(test[1]))\n",
        "\n",
        "#Display the first 40 labels\n",
        "print(train[1][:300])\n",
        "#Dispplay the first 40 speech features\n",
        "print(train[0][:40])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200000, 39) 200000\n",
            "(10000, 39) 10000\n",
            "(10000, 39) 10000\n",
            "['sil' 'sil' 'sil' 'sil' 'sil' 'sil' 'sil' 'sil' 'sil' 'sil' 'sil' 'sil'\n",
            " 'sil' 'ax' 'ax' 'ax' 'ax' 'ax' 'ax' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n",
            " 's' 's' 's' 's' 's' 's' 's' 's' 'uw' 'uw' 'uw' 'uw' 'uw' 'uw' 'uw' 'uw'\n",
            " 'uw' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'f' 'f' 'f' 'f' 'f' 'f' 'f'\n",
            " 'f' 'f' 'f' 'f' 'f' 'ao' 'ao' 'ao' 'ao' 'ao' 'ao' 'r' 'r' 'r' 'r' 'r'\n",
            " 'ix' 'ix' 'ix' 'vcl' 'vcl' 'vcl' 'vcl' 'vcl' 'z' 'z' 'z' 'z' 'z' 'z' 'z'\n",
            " 'z' 'ae' 'ae' 'ae' 'ae' 'ae' 'ae' 'ae' 'ae' 'ae' 'ae' 'm' 'm' 'm' 'm'\n",
            " 'cl' 'cl' 'cl' 'p' 'p' 'p' 'p' 'uh' 'uh' 'uh' 'l' 'l' 'l' 'l' 'l' 'l' 'l'\n",
            " 'l' 'l' 'l' 'l' 'l' 'l' 'ax' 'ax' 'ax' 'ax' 'ax' 'ax' 'ax' 's' 's' 's'\n",
            " 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 'ix' 'ix' 'ix' 'ix' 'ix' 'cl'\n",
            " 'cl' 'cl' 'ch' 'ch' 'ch' 'ch' 'ch' 'ch' 'ch' 'ch' 'ch' 'ch' 'ch' 'uw'\n",
            " 'uw' 'uw' 'uw' 'uw' 'uw' 'uw' 'uw' 'uw' 'ey' 'ey' 'ey' 'ey' 'ey' 'ey'\n",
            " 'ey' 'ey' 'ey' 'ey' 'sh' 'sh' 'sh' 'sh' 'sh' 'sh' 'sh' 'sh' 'sh' 'sh'\n",
            " 'sh' 'en' 'en' 'en' 'en' 'en' 'en' 'en' 'w' 'w' 'w' 'w' 'w' 'w' 'w' 'w'\n",
            " 'w' 'w' 'w' 'w' 'eh' 'eh' 'eh' 'er' 'er' 'er' 'er' 'er' 'f' 'f' 'f' 'f'\n",
            " 'f' 'f' 'f' 'f' 'f' 'f' 'f' 'f' 'f' 'f' 'aa' 'aa' 'aa' 'aa' 'aa' 'aa'\n",
            " 'aa' 'aa' 'aa' 'aa' 'aa' 'aa' 'aa' 'r' 'r' 'r' 'm' 'm' 'm' 'm' 'm' 'm'\n",
            " 'hh' 'hh' 'hh' 'hh' 'hh' 'hh' 'hh' 'hh' 'eh' 'eh' 'eh' 'eh' 'z' 'z' 'z'\n",
            " 'z' 'z' 'z' 'z' 'z' 'ax' 'ax' 'ax' 'ax' 'cl' 'cl' 'cl' 'p' 'p' 'p' 'p'\n",
            " 'p' 'p' 'p' 'p' 'p' 'p']\n",
            "[[-27.69561   -21.09042     1.654011  ...   0.3484999   0.768689\n",
            "    1.307443 ]\n",
            " [-28.63498   -24.11119     5.481146  ...  -0.7078144   0.1252752\n",
            "    1.01771  ]\n",
            " [-31.45311   -22.93973     2.537196  ...  -1.359528   -1.21996\n",
            "   -0.538246 ]\n",
            " ...\n",
            " [ 13.88244    -0.1123238  -9.3858    ...  -3.32069     1.63194\n",
            "   -0.6642456]\n",
            " [ 14.03307     1.899275   -9.866893  ...  -3.532823    2.024883\n",
            "   -1.48834  ]\n",
            " [ 14.1837      0.1750488  -8.502616  ...  -1.771908    2.117862\n",
            "   -1.812105 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdMvLjPWeysE",
        "colab_type": "text"
      },
      "source": [
        "Every frame has a corresponding phoneme label and our goal is to train a model to predict label of unseen frames correctly.\n",
        "\n",
        "A simple model can predict phonemes just by considering a single frame but adding context could improve the accuracy of our model. We add context by appending each frame with neighbouring frames. After that we batch our data instances for our model to leverage the parallel processing of GPU. This is done in the function below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD26HuE00XT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batchify(data_feats, data_labels, batch_size, label_dict, window=5, to_cuda=False):\n",
        "    batched_tdata = []\n",
        "    curr_batch = []\n",
        "    fz = np.zeros((window, 39))\n",
        "    bz = np.zeros((window, 39))\n",
        "    fl = ['sil'] * window\n",
        "    bl = ['sil'] * window\n",
        "    data_labels = fl + data_labels.tolist() + bl\n",
        "    data_feats = np.concatenate((fz, data_feats, bz))\n",
        "    for i in range(window, len(data_labels) - window):\n",
        "        x = data_feats[i - window: i + window + 1]\n",
        "        y = data_labels[i]\n",
        "        tx = torch.Tensor(x).unsqueeze(0) # shape should be (1, 39, 2window)\n",
        "        ty = torch.Tensor([label_dict[y]]) # shape should be (1, 1)\n",
        "        if len(curr_batch) < batch_size:\n",
        "            #if y != 'sil':\n",
        "            curr_batch.append((tx, ty))\n",
        "        else:\n",
        "            _tx, _ty = zip(*curr_batch)\n",
        "            b_tx = torch.cat(_tx, dim=0)\n",
        "            b_ty = torch.cat(_ty, dim=0)\n",
        "            if to_cuda:\n",
        "                b_tx, b_ty = b_tx.cuda(), b_ty.cuda()\n",
        "            batched_tdata.append((b_ty, b_tx))\n",
        "            curr_batch = []\n",
        "    if len(curr_batch) > 0:\n",
        "        _tx, _ty = zip(*curr_batch)\n",
        "        b_tx = torch.cat(_tx, dim=0)\n",
        "        b_ty = torch.cat(_ty, dim=0)\n",
        "        if to_cuda:\n",
        "            b_tx, b_ty = b_tx.cuda(), b_ty.cuda()\n",
        "        batched_tdata.append((b_ty, b_tx))\n",
        "    return batched_tdata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vupBGBtP06Pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window=0\n",
        "batched_train_0 = batchify(train[0], train[1], 2000, label_dict, window, True)\n",
        "batched_dev_0 = batchify(dev[0], dev[1], 2000, label_dict, window, True)\n",
        "batched_test_0 = batchify(test[0], test[1], 2000, label_dict, window, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBq9IrmQnmAP",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vegGVESpg-Km",
        "colab_type": "text"
      },
      "source": [
        "Below we will ask you to complete the definition of a simple network. You will have to write code in parts of code where #TODO is placed. You are expected to only add code. Do not change the provided code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ePRzch10gII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP_Simple(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 hidden_size,\n",
        "                 num_labels):\n",
        "        super().__init__()\n",
        "        # Just single frame, therefore, 1 * 39\n",
        "        self.layer0 = torch.nn.Linear(1 * 39, hidden_size)\n",
        "\n",
        "        \n",
        "        # Do not change the surrounding code, only add yours\n",
        "        #TODO: Add more layers and activations here...\n",
        "        \n",
        "        self.final_layer = torch.nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Generate output distribution and argmax\n",
        "        Args:\n",
        "            x: num frames of 39-dimensional feature vector (MFCC features)\n",
        "        Return:\n",
        "            dist: log probability for each output class\n",
        "            pred: the label with highest log probability\n",
        "        \"\"\"\n",
        "        batch_size, frames, features = x.shape\n",
        "        x = x.squeeze(1)\n",
        "        x = self.layer0(x)\n",
        "\n",
        "        # TODO: use your defined layers here.\n",
        "      \n",
        "\n",
        "        y_hat = self.final_layer(x) # shape should be (batch_size, label_size)\n",
        "        _, y_pred = y_hat.max(dim=-1) # y_pred shape should be (batch_size, 1)\n",
        "        return y_hat, y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWgvEGfalTuO",
        "colab_type": "text"
      },
      "source": [
        "Here we create an instance of our simple model that uses single frame without context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVg6n6LTN9-F",
        "colab_type": "code",
        "outputId": "17d81e09-9722-4778-95a2-cfa0dd0a7b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model_simple = MLP_Simple(hidden_size=512, num_labels=len(label_dict))\n",
        "print(model_simple)\n",
        "print('num parameters:', sum([p.numel() for p in model_simple.parameters()]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP_Simple(\n",
            "  (layer0): Linear(in_features=39, out_features=512, bias=True)\n",
            "  (final_layer): Linear(in_features=512, out_features=48, bias=True)\n",
            ")\n",
            "num parameters: 45104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0lS_yUqnyAp",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKq6F0_AmRLu",
        "colab_type": "text"
      },
      "source": [
        "Here we define a function `train_model` that performs optimization of model's parameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tpB--OO4zr0",
        "colab_type": "code",
        "outputId": "fcd7625b-e66b-4f2e-b69b-a3c16a49c11c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def train_model(model, batched_train, batched_dev, batched_test, max_epoch=20):\n",
        "    model = model.cuda()\n",
        "    loss = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "    optim = torch.optim.Adam(model.parameters())\n",
        "  \n",
        "    for epoch in range(max_epoch):\n",
        "        random.shuffle(batched_train)\n",
        "        train_loss = []\n",
        "        train_acc = []\n",
        "        model.train()\n",
        "        for batch in batched_train:\n",
        "            optim.zero_grad()\n",
        "            y, x = batch\n",
        "            y_hat, y_pred = model(x)\n",
        "            batch_loss = loss(y_hat, y.long())\n",
        "            batch_loss.backward()\n",
        "            optim.step()\n",
        "            batch_acc = (y_pred == y.long()).sum().item() / y.numel()\n",
        "            train_loss.append(batch_loss.item())\n",
        "            train_acc.append(batch_acc)\n",
        "        _loss = sum(train_loss) / len(train_loss)\n",
        "        _acc = sum(train_acc) / len(train_acc)\n",
        "        print(f\"Epoch {epoch}\")\n",
        "        print(f\"train loss {_loss:.4f} train_acc {_acc:.4f}\")\n",
        "        dev_acc = []\n",
        "        model.eval()\n",
        "        for batch in batched_dev:\n",
        "            y, x = batch\n",
        "            with torch.no_grad():\n",
        "                y_hat, y_pred = model(x)\n",
        "                batch_acc = (y_pred == y.long()).sum().item() / y.numel()\n",
        "                dev_acc.append(batch_acc)\n",
        "        _acc = sum(dev_acc) / len(dev_acc)\n",
        "        print(f\"dev_acc {_acc:.4f}\")\n",
        "    test_acc = []\n",
        "    model.eval()\n",
        "    for batch in batched_test:\n",
        "        y, x = batch\n",
        "        with torch.no_grad():\n",
        "            y_hat, y_pred = model(x)\n",
        "            batch_acc = (y_pred == y.long()).sum().item() / y.numel()\n",
        "            test_acc.append(batch_acc)\n",
        "    _acc = sum(test_acc) / len(test_acc)\n",
        "    print(f\"training completed.\\n\")\n",
        "    print(f\"test_acc {_acc:.4f}\")\n",
        "\n",
        "train_model(model_simple, batched_train_0, batched_dev_0, batched_test_0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "train loss 0.5294 train_acc 0.8144\n",
            "dev_acc 0.5768\n",
            "Epoch 1\n",
            "train loss 0.4947 train_acc 0.8285\n",
            "dev_acc 0.5682\n",
            "Epoch 2\n",
            "train loss 0.4865 train_acc 0.8319\n",
            "dev_acc 0.5718\n",
            "Epoch 3\n",
            "train loss 0.4807 train_acc 0.8327\n",
            "dev_acc 0.5720\n",
            "Epoch 4\n",
            "train loss 0.4651 train_acc 0.8374\n",
            "dev_acc 0.5664\n",
            "Epoch 5\n",
            "train loss 0.4525 train_acc 0.8419\n",
            "dev_acc 0.5699\n",
            "Epoch 6\n",
            "train loss 0.4426 train_acc 0.8464\n",
            "dev_acc 0.5772\n",
            "Epoch 7\n",
            "train loss 0.4207 train_acc 0.8536\n",
            "dev_acc 0.5640\n",
            "Epoch 8\n",
            "train loss 0.4172 train_acc 0.8542\n",
            "dev_acc 0.5678\n",
            "Epoch 9\n",
            "train loss 0.4065 train_acc 0.8593\n",
            "dev_acc 0.5648\n",
            "Epoch 10\n",
            "train loss 0.3941 train_acc 0.8629\n",
            "dev_acc 0.5538\n",
            "Epoch 11\n",
            "train loss 0.3834 train_acc 0.8668\n",
            "dev_acc 0.5668\n",
            "Epoch 12\n",
            "train loss 0.3720 train_acc 0.8697\n",
            "dev_acc 0.5628\n",
            "Epoch 13\n",
            "train loss 0.3715 train_acc 0.8699\n",
            "dev_acc 0.5635\n",
            "Epoch 14\n",
            "train loss 0.3572 train_acc 0.8748\n",
            "dev_acc 0.5681\n",
            "Epoch 15\n",
            "train loss 0.3519 train_acc 0.8768\n",
            "dev_acc 0.5712\n",
            "Epoch 16\n",
            "train loss 0.3468 train_acc 0.8786\n",
            "dev_acc 0.5639\n",
            "Epoch 17\n",
            "train loss 0.3282 train_acc 0.8856\n",
            "dev_acc 0.5604\n",
            "Epoch 18\n",
            "train loss 0.3177 train_acc 0.8900\n",
            "dev_acc 0.5708\n",
            "Epoch 19\n",
            "train loss 0.3149 train_acc 0.8902\n",
            "dev_acc 0.5665\n",
            "training completed.\n",
            "\n",
            "test_acc 0.5948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0JrP5z0oG_G",
        "colab_type": "text"
      },
      "source": [
        "# Adding Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umr7Koj6oV6d",
        "colab_type": "text"
      },
      "source": [
        "Next, we will look at the effect of more context on model performance. The segment below creates batched data with neighboring 5 frames from left and right (of the key frame, making 11 frames in total)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJRf2MyroRXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window=5\n",
        "batched_train_5 = batchify(train[0], train[1], 2000, label_dict, window, True)\n",
        "batched_dev_5 = batchify(dev[0], dev[1], 2000, label_dict, window, True)\n",
        "batched_test_5 = batchify(test[0], test[1], 2000, label_dict, window, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6lbbZ4Aon05",
        "colab_type": "code",
        "outputId": "291e8e20-2785-42f5-a762-760a3aa7c1bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "class MLP_Context(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 hidden_size,\n",
        "                 num_labels,\n",
        "                 window_size=5):\n",
        "        super().__init__()\n",
        "        self.layer0 = torch.nn.Linear((2 * window_size + 1) * 39, hidden_size)\n",
        "\n",
        "        \n",
        "        # Do not change the surrounding code, only add yours\n",
        "        #TODO: Add more layers and activations here...\n",
        "\n",
        "        self.final_layer = torch.nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Generate output distribution and argmax\n",
        "        Args:\n",
        "            x: num frames of 39-dimensional feature vector (MFCC features)\n",
        "        Return:\n",
        "            dist: log probability for each output class\n",
        "            pred: the label with highest log probability\n",
        "        \"\"\"\n",
        "        batch_size, frames, features = x.shape\n",
        "        x = x.view(batch_size, -1)\n",
        "        x = self.layer0(x)\n",
        "\n",
        "        # TODO: use your defined layer\n",
        "\n",
        "        y_hat = self.final_layer(x) # shape should be (batch_size, label_size)\n",
        "        _, y_pred = y_hat.max(dim=-1) # y_pred shape should be (batch_size, 1)\n",
        "        return y_hat, y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-24ebbd500fd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMLP_Context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     def __init__(self,\n\u001b[1;32m      3\u001b[0m                  \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  window_size=5):\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM2PBTqKpLE4",
        "colab_type": "code",
        "outputId": "3135a4b1-75ed-43c2-8d30-e528369c42bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_context = MLP_Context(hidden_size=512, num_labels=len(label_dict))\n",
        "train_model(model_context, batched_train_5, batched_dev_5, batched_test_5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "train loss 1.6566 train_acc 0.5111\n",
            "dev_acc 0.5609\n",
            "Epoch 1\n",
            "train loss 1.2214 train_acc 0.6140\n",
            "dev_acc 0.6009\n",
            "Epoch 2\n",
            "train loss 1.0732 train_acc 0.6553\n",
            "dev_acc 0.6154\n",
            "Epoch 3\n",
            "train loss 0.9835 train_acc 0.6793\n",
            "dev_acc 0.6286\n",
            "Epoch 4\n",
            "train loss 0.9218 train_acc 0.6963\n",
            "dev_acc 0.6070\n",
            "Epoch 5\n",
            "train loss 0.8723 train_acc 0.7096\n",
            "dev_acc 0.6226\n",
            "Epoch 6\n",
            "train loss 0.8189 train_acc 0.7257\n",
            "dev_acc 0.6383\n",
            "Epoch 7\n",
            "train loss 0.7638 train_acc 0.7441\n",
            "dev_acc 0.6465\n",
            "Epoch 8\n",
            "train loss 0.7176 train_acc 0.7568\n",
            "dev_acc 0.6550\n",
            "Epoch 9\n",
            "train loss 0.6761 train_acc 0.7706\n",
            "dev_acc 0.6464\n",
            "Epoch 10\n",
            "train loss 0.6372 train_acc 0.7824\n",
            "dev_acc 0.6450\n",
            "Epoch 11\n",
            "train loss 0.6010 train_acc 0.7948\n",
            "dev_acc 0.6519\n",
            "Epoch 12\n",
            "train loss 0.5649 train_acc 0.8057\n",
            "dev_acc 0.6366\n",
            "Epoch 13\n",
            "train loss 0.5313 train_acc 0.8165\n",
            "dev_acc 0.6462\n",
            "Epoch 14\n",
            "train loss 0.5080 train_acc 0.8239\n",
            "dev_acc 0.6434\n",
            "Epoch 15\n",
            "train loss 0.4506 train_acc 0.8442\n",
            "dev_acc 0.6451\n",
            "Epoch 16\n",
            "train loss 0.4223 train_acc 0.8520\n",
            "dev_acc 0.6256\n",
            "Epoch 17\n",
            "train loss 0.3931 train_acc 0.8623\n",
            "dev_acc 0.6320\n",
            "Epoch 18\n",
            "train loss 0.3653 train_acc 0.8711\n",
            "dev_acc 0.6379\n",
            "Epoch 19\n",
            "train loss 0.3394 train_acc 0.8806\n",
            "dev_acc 0.6338\n",
            "training completed.\n",
            "\n",
            "test_acc 0.6549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-6La2_Dqm-i",
        "colab_type": "text"
      },
      "source": [
        "## Tasks\n",
        "\n",
        "\n",
        "1. Explore with different number of layers and hidden sizes for a window size of 5.\n",
        "\n",
        "2. Explore different window sizes and report the one that worked best for you. Does increasing the context help?\n",
        "\n",
        "3. (Optional) Write code below, trying to implement model based on convolutions and see if it performs better compared to the one with fully connected layers. You might find [this](https://pytorch.org/docs/stable/nn.html?highlight=conv1d#torch.nn.Conv1d) helpful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIx0FOYVtZlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cells for optional part."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}